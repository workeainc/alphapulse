"""
Real Data Integration Service for AlphaPulse
Phase 5B: Cadence Implementation

Integrates with:
1. TimescaleDB for historical market data
2. Redis for real-time data and caching
3. External APIs for live market data
4. Data validation and quality checks
"""

import asyncio
import logging
from typing import Dict, List, Optional, Any, Tuple, Union
from datetime import datetime, timedelta
import pandas as pd
import numpy as np
from pathlib import Path
import json
import hashlib
import time
import psycopg2
from psycopg2.extras import RealDictCursor
import redis.asyncio as redis

# External API imports with error handling
try:
    import ccxt
    CCXT_AVAILABLE = True
except (ImportError, AttributeError) as e:
    CCXT_AVAILABLE = False
    logging.warning(f"CCXT not available - external exchange data disabled: {e}")

try:
    import yfinance as yf
    YFINANCE_AVAILABLE = True
except (ImportError, AttributeError) as e:
    YFINANCE_AVAILABLE = False
    logging.warning(f"yfinance not available - Yahoo Finance data disabled: {e}")

# Additional SSL compatibility check
try:
    import ssl
    # Test SSL functionality
    ssl.create_default_context()
    SSL_AVAILABLE = True
except (ImportError, AttributeError) as e:
    SSL_AVAILABLE = False
    logging.warning(f"SSL not available - external API calls disabled: {e}")
    # Disable external APIs if SSL is problematic
    CCXT_AVAILABLE = False
    YFINANCE_AVAILABLE = False

# Local imports
from ..src.core.prefect_config import prefect_settings
from .advanced_logging_system import redis_logger, EventType, LogLevel

logger = logging.getLogger(__name__)

class RealDataIntegrationService:
    """
    Service for integrating with real data sources
    Provides actual market data for model retraining
    """
    
    def __init__(self):
        # Database connections
        self.timescale_conn = None
        self.redis_client = None
        
        # Data source configuration
        self.data_sources = {
            'timescaledb': {
                'enabled': True,
                'host': 'localhost',
                'port': 5432,
                'database': 'alphapulse',
                'user': 'postgres',
                'password': 'password'
            },
            'redis': {
                'enabled': True,
                'host': 'localhost',
                'port': 6379,
                'db': 0
            },
            'external_apis': {
                'enabled': True,
                'ccxt_exchanges': ['binance', 'coinbase', 'kraken'] if CCXT_AVAILABLE else [],
                'yfinance_symbols': ['BTC-USD', 'ETH-USD', 'ADA-USD', 'DOT-USD', 'LINK-USD'] if YFINANCE_AVAILABLE else []
            }
        }
        
        # Data quality thresholds
        self.quality_thresholds = {
            'min_data_points': {
                'weekly_quick': 1000,
                'monthly_full': 5000,
                'nightly_incremental': 100
            },
            'min_feature_completeness': 0.95,
            'max_missing_values': 0.05,
            'min_data_quality_score': 0.8,
            'max_data_age_hours': 24  # Max age of data in hours
        }
        
        # Cache configuration
        self.cache_ttl = prefect_settings.DATA_CACHE_TTL
        self.data_cache = {}
        
        # Performance tracking
        self.query_times = []
        self.data_volumes = []
        
        logger.info("üöÄ Real Data Integration Service initialized")
    
    async def initialize(self):
        """Initialize database connections"""
        try:
            logger.info("üîå Initializing database connections...")

            # Check SSL compatibility first
            if not SSL_AVAILABLE:
                logger.warning("‚ö†Ô∏è SSL not available - external APIs disabled")
                self.data_sources['external_apis']['enabled'] = False

            # Initialize TimescaleDB connection
            if self.data_sources['timescaledb']['enabled']:
                await self._init_timescaledb()

            # Initialize Redis connection
            if self.data_sources['redis']['enabled']:
                await self._init_redis()

            logger.info("‚úÖ Database connections initialized successfully")

        except Exception as e:
            logger.error(f"‚ùå Failed to initialize database connections: {e}")
            # Don't raise - allow service to continue with fallback data
    
    async def _init_timescaledb(self):
        """Initialize TimescaleDB connection"""
        try:
            config = self.data_sources['timescaledb']
            
            # Create connection
            self.timescale_conn = psycopg2.connect(
                host=config['host'],
                port=config['port'],
                database=config['database'],
                user=config['user'],
                password=config['password']
            )
            
            # Test connection
            with self.timescale_conn.cursor() as cursor:
                cursor.execute("SELECT version();")
                version = cursor.fetchone()
                logger.info(f"‚úÖ TimescaleDB connected: {version[0]}")
                
        except Exception as e:
            logger.error(f"‚ùå Failed to connect to TimescaleDB: {e}")
            self.timescale_conn = None
    
    async def _init_redis(self):
        """Initialize Redis connection"""
        try:
            config = self.data_sources['redis']
            
            # Create Redis client
            self.redis_client = redis.Redis(
                host=config['host'],
                port=config['port'],
                db=config['db'],
                decode_responses=True
            )
            
            # Test connection
            await self.redis_client.ping()
            logger.info(f"‚úÖ Redis connected: {config['host']}:{config['port']}")
            
        except Exception as e:
            logger.error(f"‚ùå Failed to connect to Redis: {e}")
            self.redis_client = None
    
    async def get_market_data(self,
                             symbols: List[str],
                             start_date: datetime,
                             end_date: datetime,
                             timeframe: str = '1h') -> Optional[pd.DataFrame]:
        """
        Get market data from TimescaleDB
        
        Args:
            symbols: List of trading symbols
            start_date: Start date for data collection
            end_date: End date for data collection
            timeframe: Data timeframe (1m, 5m, 15m, 1h, 4h, 1d)
            
        Returns:
            Market data DataFrame or None
        """
        try:
            if self.timescale_conn is None:
                logger.warning("‚ö†Ô∏è TimescaleDB not connected, using fallback data")
                return await self._get_fallback_market_data(symbols, start_date, end_date, timeframe)
            
            logger.info(f"üìä Fetching market data for {len(symbols)} symbols from {start_date} to {end_date}")
            
            # Build query for each symbol
            all_data = []
            
            for symbol in symbols:
                symbol_data = await self._query_symbol_data(symbol, start_date, end_date, timeframe)
                if symbol_data is not None and len(symbol_data) > 0:
                    all_data.append(symbol_data)
            
            if not all_data:
                logger.warning("‚ö†Ô∏è No market data found")
                return None
            
            # Combine all symbol data
            combined_data = pd.concat(all_data, ignore_index=True)
            
            # Sort by timestamp
            combined_data = combined_data.sort_values('timestamp').reset_index(drop=True)
            
            logger.info(f"‚úÖ Retrieved {len(combined_data)} market data records")
            return combined_data
            
        except Exception as e:
            logger.error(f"Error getting market data: {e}")
            return None
    
    async def _query_symbol_data(self,
                                symbol: str,
                                start_date: datetime,
                                end_date: datetime,
                                timeframe: str) -> Optional[pd.DataFrame]:
        """Query data for a specific symbol from TimescaleDB"""
        try:
            # Convert timeframe to interval
            interval_map = {
                '1m': '1 minute',
                '5m': '5 minutes',
                '15m': '15 minutes',
                '1h': '1 hour',
                '4h': '4 hours',
                '1d': '1 day'
            }
            
            interval = interval_map.get(timeframe, '1 hour')
            
            # SQL query for TimescaleDB
            query = """
            SELECT 
                timestamp,
                symbol,
                open,
                high,
                low,
                close,
                volume,
                vwap,
                trade_count
            FROM market_data 
            WHERE symbol = %s 
                AND timestamp >= %s 
                AND timestamp <= %s
            ORDER BY timestamp
            """
            
            with self.timescale_conn.cursor(cursor_factory=RealDictCursor) as cursor:
                cursor.execute(query, (symbol, start_date, end_date))
                rows = cursor.fetchall()
            
            if not rows:
                return None
            
            # Convert to DataFrame
            df = pd.DataFrame(rows)
            
            # Add technical indicators
            df = await self._add_technical_indicators(df)
            
            return df
            
        except Exception as e:
            logger.error(f"Error querying data for {symbol}: {e}")
            return None
    
    async def _add_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """Add technical indicators to market data"""
        try:
            if len(df) < 20:  # Need minimum data for indicators
                return df
            
            # Calculate RSI
            df['rsi'] = self._calculate_rsi(df['close'], period=14)
            
            # Calculate MACD
            macd_data = self._calculate_macd(df['close'])
            df['macd'] = macd_data['macd']
            df['macd_signal'] = macd_data['signal']
            df['macd_histogram'] = macd_data['histogram']
            
            # Calculate Bollinger Bands
            bb_data = self._calculate_bollinger_bands(df['close'])
            df['bb_upper'] = bb_data['upper']
            df['bb_middle'] = bb_data['middle']
            df['bb_lower'] = bb_data['lower']
            
            # Calculate volume indicators
            df['volume_sma'] = df['volume'].rolling(window=20).mean()
            df['volume_ratio'] = df['volume'] / df['volume_sma']
            
            # Calculate price changes
            df['price_change'] = df['close'].pct_change()
            df['price_change_5'] = df['close'].pct_change(periods=5)
            df['price_change_20'] = df['close'].pct_change(periods=20)
            
            return df
            
        except Exception as e:
            logger.error(f"Error adding technical indicators: {e}")
            return df
    
    def _calculate_rsi(self, prices: pd.Series, period: int = 14) -> pd.Series:
        """Calculate RSI indicator"""
        try:
            delta = prices.diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
            rs = gain / loss
            rsi = 100 - (100 / (1 + rs))
            return rsi
        except Exception:
            return pd.Series([np.nan] * len(prices))
    
    def _calculate_macd(self, prices: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9) -> Dict[str, pd.Series]:
        """Calculate MACD indicator"""
        try:
            ema_fast = prices.ewm(span=fast).mean()
            ema_slow = prices.ewm(span=slow).mean()
            macd = ema_fast - ema_slow
            signal_line = macd.ewm(span=signal).mean()
            histogram = macd - signal_line
            
            return {
                'macd': macd,
                'signal': signal_line,
                'histogram': histogram
            }
        except Exception:
            nan_series = pd.Series([np.nan] * len(prices))
            return {
                'macd': nan_series,
                'signal': nan_series,
                'histogram': nan_series
            }
    
    def _calculate_bollinger_bands(self, prices: pd.Series, period: int = 20, std_dev: float = 2) -> Dict[str, pd.Series]:
        """Calculate Bollinger Bands"""
        try:
            sma = prices.rolling(window=period).mean()
            std = prices.rolling(window=period).std()
            
            upper = sma + (std * std_dev)
            lower = sma - (std * std_dev)
            
            return {
                'upper': upper,
                'middle': sma,
                'lower': lower
            }
        except Exception:
            nan_series = pd.Series([np.nan] * len(prices))
            return {
                'upper': nan_series,
                'middle': nan_series,
                'lower': nan_series
            }
    
    async def _get_fallback_market_data(self,
                                       symbols: List[str],
                                       start_date: datetime,
                                       end_date: datetime,
                                       timeframe: str) -> Optional[pd.DataFrame]:
        """Get fallback market data when TimescaleDB is unavailable"""
        try:
            logger.info("üîÑ Using fallback market data sources...")
            
            all_data = []
            
            for symbol in symbols:
                # Try yfinance first if available
                symbol_data = None
                if YFINANCE_AVAILABLE:
                    symbol_data = await self._get_yfinance_data(symbol, start_date, end_date, timeframe)
                
                if symbol_data is None or len(symbol_data) == 0:
                    # Try CCXT as backup if available
                    if CCXT_AVAILABLE:
                        symbol_data = await self._get_ccxt_data(symbol, start_date, end_date, timeframe)
                
                if symbol_data is None or len(symbol_data) == 0:
                    # Generate synthetic data as last resort
                    symbol_data = self._generate_synthetic_data(symbol, start_date, end_date, timeframe)
                
                if symbol_data is not None and len(symbol_data) > 0:
                    all_data.append(symbol_data)
            
            if not all_data:
                logger.warning("‚ö†Ô∏è No fallback data available")
                return None
            
            # Combine all data
            combined_data = pd.concat(all_data, ignore_index=True)
            combined_data = combined_data.sort_values('timestamp').reset_index(drop=True)
            
            logger.info(f"‚úÖ Retrieved {len(combined_data)} fallback data records")
            return combined_data
            
        except Exception as e:
            logger.error(f"Error getting fallback data: {e}")
            return None
    
    def _generate_synthetic_data(self,
                                symbol: str,
                                start_date: datetime,
                                end_date: datetime,
                                timeframe: str) -> pd.DataFrame:
        """Generate synthetic market data for testing"""
        try:
            # Generate date range
            if timeframe == '1h':
                date_range = pd.date_range(start=start_date, end=end_date, freq='1H')
            elif timeframe == '1d':
                date_range = pd.date_range(start=start_date, end=end_date, freq='1D')
            else:
                date_range = pd.date_range(start=start_date, end=end_date, freq='1H')
            
            # Generate synthetic OHLCV data
            data = []
            base_price = 100.0
            
            for timestamp in date_range:
                # Random price movement
                price_change = np.random.normal(0, 0.02)  # 2% volatility
                base_price *= (1 + price_change)
                
                # Generate OHLCV
                high = base_price * (1 + abs(np.random.normal(0, 0.01)))
                low = base_price * (1 - abs(np.random.normal(0, 0.01)))
                open_price = base_price * (1 + np.random.normal(0, 0.005))
                close_price = base_price
                volume = np.random.uniform(1000, 10000)
                
                data.append({
                    'timestamp': timestamp,
                    'symbol': symbol,
                    'open': open_price,
                    'high': high,
                    'low': low,
                    'close': close_price,
                    'volume': volume
                })
            
            df = pd.DataFrame(data)
            
            # Add technical indicators
            df = self._add_technical_indicators_sync(df)
            
            return df
            
        except Exception as e:
            logger.error(f"Error generating synthetic data: {e}")
            return pd.DataFrame()
    
    def _add_technical_indicators_sync(self, df: pd.DataFrame) -> pd.DataFrame:
        """Add technical indicators synchronously"""
        try:
            if len(df) < 20:
                return df
            
            # Calculate RSI
            df['rsi'] = self._calculate_rsi(df['close'], period=14)
            
            # Calculate MACD
            macd_data = self._calculate_macd(df['close'])
            df['macd'] = macd_data['macd']
            df['macd_signal'] = macd_data['signal']
            df['macd_histogram'] = macd_data['histogram']
            
            # Calculate Bollinger Bands
            bb_data = self._calculate_bollinger_bands(df['close'])
            df['bb_upper'] = bb_data['upper']
            df['bb_middle'] = bb_data['middle']
            df['bb_lower'] = bb_data['lower']
            
            # Calculate volume indicators
            df['volume_sma'] = df['volume'].rolling(window=20).mean()
            df['volume_ratio'] = df['volume'] / df['volume_sma']
            
            # Calculate price changes
            df['price_change'] = df['close'].pct_change()
            df['price_change_5'] = df['close'].pct_change(periods=5)
            df['price_change_20'] = df['close'].pct_change(periods=20)
            
            return df
            
        except Exception as e:
            logger.error(f"Error adding technical indicators: {e}")
            return df
    
    async def _get_yfinance_data(self,
                                 symbol: str,
                                 start_date: datetime,
                                 end_date: datetime,
                                 timeframe: str) -> Optional[pd.DataFrame]:
        """Get data from Yahoo Finance"""
        if not YFINANCE_AVAILABLE or not SSL_AVAILABLE:
            return None
        
        try:
            # Convert timeframe to yfinance interval
            interval_map = {
                '1m': '1m',
                '5m': '5m',
                '15m': '15m',
                '1h': '1h',
                '4h': '1d',  # yfinance doesn't support 4h
                '1d': '1d'
            }
            
            interval = interval_map.get(timeframe, '1h')
            
            # Get data from yfinance
            ticker = yf.Ticker(symbol)
            data = ticker.history(start=start_date, end=end_date, interval=interval)
            
            if data.empty:
                return None
            
            # Reset index to get timestamp as column
            data = data.reset_index()
            
            # Rename columns to match our schema
            data = data.rename(columns={
                'Datetime': 'timestamp',
                'Open': 'open',
                'High': 'high',
                'Low': 'low',
                'Close': 'close',
                'Volume': 'volume'
            })
            
            # Add symbol column
            data['symbol'] = symbol
            
            # Add technical indicators
            data = self._add_technical_indicators_sync(data)
            
            return data
            
        except Exception as e:
            logger.error(f"Error getting yfinance data for {symbol}: {e}")
            return None
    
    async def _get_ccxt_data(self,
                             symbol: str,
                             start_date: datetime,
                             end_date: datetime,
                             timeframe: str) -> Optional[pd.DataFrame]:
        """Get data from CCXT exchanges"""
        if not CCXT_AVAILABLE or not SSL_AVAILABLE:
            return None
            
        try:
            # Try different exchanges
            for exchange_name in self.data_sources['external_apis']['ccxt_exchanges']:
                try:
                    exchange = getattr(ccxt, exchange_name)()
                    
                    # Convert timeframe to exchange format
                    timeframe_map = {
                        '1m': '1m',
                        '5m': '5m',
                        '15m': '15m',
                        '1h': '1h',
                        '4h': '4h',
                        '1d': '1d'
                    }
                    
                    exchange_timeframe = timeframe_map.get(timeframe, '1h')
                    
                    # Get OHLCV data
                    ohlcv = exchange.fetch_ohlcv(
                        symbol,
                        exchange_timeframe,
                        int(start_date.timestamp() * 1000),
                        limit=1000
                    )
                    
                    if ohlcv and len(ohlcv) > 0:
                        # Convert to DataFrame
                        df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
                        
                        # Convert timestamp from milliseconds to datetime
                        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
                        
                        # Filter by date range
                        df = df[(df['timestamp'] >= start_date) & (df['timestamp'] <= end_date)]
                        
                        if len(df) > 0:
                            # Add symbol column
                            df['symbol'] = symbol
                            
                            # Add technical indicators
                            df = self._add_technical_indicators_sync(df)
                            
                            logger.info(f"‚úÖ Retrieved {len(df)} records from {exchange_name}")
                            return df
                
                except Exception as e:
                    logger.debug(f"Failed to get data from {exchange_name}: {e}")
                    continue
            
            return None
            
        except Exception as e:
            logger.error(f"Error getting CCXT data for {symbol}: {e}")
            return None
    
    async def get_sentiment_data(self,
                                symbols: List[str],
                                start_date: datetime,
                                end_date: datetime) -> Optional[pd.DataFrame]:
        """Get sentiment data from Redis or external sources"""
        try:
            if self.redis_client is None:
                logger.warning("‚ö†Ô∏è Redis not connected, skipping sentiment data")
                return None
            
            logger.info(f"üìä Fetching sentiment data for {len(symbols)} symbols")
            
            all_sentiment = []
            
            for symbol in symbols:
                # Try to get sentiment from Redis
                sentiment_key = f"sentiment:{symbol}:{start_date.strftime('%Y%m%d')}"
                sentiment_data = await self.redis_client.get(sentiment_key)
                
                if sentiment_data:
                    try:
                        sentiment_dict = json.loads(sentiment_data)
                        sentiment_dict['symbol'] = symbol
                        sentiment_dict['timestamp'] = start_date
                        all_sentiment.append(sentiment_dict)
                    except json.JSONDecodeError:
                        continue
            
            if not all_sentiment:
                logger.warning("‚ö†Ô∏è No sentiment data available")
                return None
            
            # Convert to DataFrame
            sentiment_df = pd.DataFrame(all_sentiment)
            
            logger.info(f"‚úÖ Retrieved {len(sentiment_df)} sentiment records")
            return sentiment_df
            
        except Exception as e:
            logger.error(f"Error getting sentiment data: {e}")
            return None
    
    async def get_market_regime_data(self,
                                   symbols: List[str],
                                   start_date: datetime,
                                   end_date: datetime) -> Optional[pd.DataFrame]:
        """Get market regime classification data"""
        try:
            logger.info(f"üìä Fetching market regime data for {len(symbols)} symbols")
            
            # This would integrate with your market regime detection system
            # For now, return None to use fallback logic
            
            return None
            
        except Exception as e:
            logger.error(f"Error getting market regime data: {e}")
            return None
    
    async def validate_data_quality(self, data: pd.DataFrame, cadence_type: str) -> bool:
        """Validate data quality meets requirements"""
        try:
            if data is None or len(data) == 0:
                return False
            
            # Check minimum data points
            min_points = self.quality_thresholds['min_data_points'][cadence_type]
            if len(data) < min_points:
                logger.warning(f"‚ö†Ô∏è Insufficient data points: {len(data)} < {min_points}")
                return False
            
            # Check data age
            if 'timestamp' in data.columns:
                latest_timestamp = data['timestamp'].max()
                data_age_hours = (datetime.now() - latest_timestamp).total_seconds() / 3600
                
                if data_age_hours > self.quality_thresholds['max_data_age_hours']:
                    logger.warning(f"‚ö†Ô∏è Data too old: {data_age_hours:.1f} hours")
                    return False
            
            # Check feature completeness
            numeric_cols = data.select_dtypes(include=[np.number]).columns
            if len(numeric_cols) < 5:  # Need at least 5 numeric features
                logger.warning("‚ö†Ô∏è Insufficient numeric features")
                return False
            
            # Check missing values
            missing_pct = data.isnull().sum().sum() / (len(data) * len(data.columns))
            if missing_pct > self.quality_thresholds['max_missing_values']:
                logger.warning(f"‚ö†Ô∏è Too many missing values: {missing_pct:.2%}")
                return False
            
            logger.info(f"‚úÖ Data quality validation passed for {cadence_type}")
            return True
            
        except Exception as e:
            logger.error(f"Error validating data quality: {e}")
            return False
    
    async def close_connections(self):
        """Close database connections"""
        try:
            if self.timescale_conn:
                self.timescale_conn.close()
                logger.info("‚úÖ TimescaleDB connection closed")
            
            if self.redis_client:
                await self.redis_client.close()
                logger.info("‚úÖ Redis connection closed")
                
        except Exception as e:
            logger.error(f"Error closing connections: {e}")
    
    def get_status(self) -> Dict[str, Any]:
        """Get service status"""
        return {
            'timescaledb_connected': self.timescale_conn is not None,
            'redis_connected': self.redis_client is not None,
            'cache_size': len(self.data_cache),
            'data_sources': self.data_sources,
            'quality_thresholds': self.quality_thresholds,
            'external_apis_available': {
                'ccxt': CCXT_AVAILABLE,
                'yfinance': YFINANCE_AVAILABLE
            }
        }

# Global service instance
real_data_integration_service = RealDataIntegrationService()
